{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.844559585492227,
  "eval_steps": 500,
  "global_step": 7600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06,
      "grad_norm": 801.4196166992188,
      "learning_rate": 9.944300518134717e-06,
      "loss": 2.7028,
      "step": 50
    },
    {
      "epoch": 0.13,
      "grad_norm": 211.7074737548828,
      "learning_rate": 9.879533678756477e-06,
      "loss": 1.2563,
      "step": 100
    },
    {
      "epoch": 0.19,
      "grad_norm": 146.43296813964844,
      "learning_rate": 9.81476683937824e-06,
      "loss": 0.9012,
      "step": 150
    },
    {
      "epoch": 0.26,
      "grad_norm": 109.8099136352539,
      "learning_rate": 9.75e-06,
      "loss": 0.7897,
      "step": 200
    },
    {
      "epoch": 0.32,
      "grad_norm": 40.516143798828125,
      "learning_rate": 9.685233160621762e-06,
      "loss": 0.8484,
      "step": 250
    },
    {
      "epoch": 0.39,
      "grad_norm": 107.91470336914062,
      "learning_rate": 9.620466321243524e-06,
      "loss": 0.7449,
      "step": 300
    },
    {
      "epoch": 0.45,
      "grad_norm": 118.63976287841797,
      "learning_rate": 9.555699481865286e-06,
      "loss": 0.7489,
      "step": 350
    },
    {
      "epoch": 0.52,
      "grad_norm": 26.958589553833008,
      "learning_rate": 9.490932642487047e-06,
      "loss": 0.7576,
      "step": 400
    },
    {
      "epoch": 0.58,
      "grad_norm": 54.47608184814453,
      "learning_rate": 9.42616580310881e-06,
      "loss": 0.7607,
      "step": 450
    },
    {
      "epoch": 0.65,
      "grad_norm": 114.89382934570312,
      "learning_rate": 9.36139896373057e-06,
      "loss": 0.7354,
      "step": 500
    },
    {
      "epoch": 0.71,
      "grad_norm": 66.61680603027344,
      "learning_rate": 9.296632124352332e-06,
      "loss": 0.7088,
      "step": 550
    },
    {
      "epoch": 0.78,
      "grad_norm": 55.348175048828125,
      "learning_rate": 9.231865284974094e-06,
      "loss": 0.7151,
      "step": 600
    },
    {
      "epoch": 0.84,
      "grad_norm": 36.96708297729492,
      "learning_rate": 9.167098445595856e-06,
      "loss": 0.7802,
      "step": 650
    },
    {
      "epoch": 0.91,
      "grad_norm": 73.83518981933594,
      "learning_rate": 9.102331606217617e-06,
      "loss": 0.7313,
      "step": 700
    },
    {
      "epoch": 0.97,
      "grad_norm": 81.17781829833984,
      "learning_rate": 9.037564766839379e-06,
      "loss": 0.6522,
      "step": 750
    },
    {
      "epoch": 1.04,
      "grad_norm": 97.83403015136719,
      "learning_rate": 8.972797927461141e-06,
      "loss": 0.6472,
      "step": 800
    },
    {
      "epoch": 1.1,
      "grad_norm": 61.083805084228516,
      "learning_rate": 8.908031088082902e-06,
      "loss": 0.6496,
      "step": 850
    },
    {
      "epoch": 1.17,
      "grad_norm": 48.81671142578125,
      "learning_rate": 8.843264248704664e-06,
      "loss": 0.7196,
      "step": 900
    },
    {
      "epoch": 1.23,
      "grad_norm": 81.46529388427734,
      "learning_rate": 8.778497409326425e-06,
      "loss": 0.6992,
      "step": 950
    },
    {
      "epoch": 1.3,
      "grad_norm": 19.2363224029541,
      "learning_rate": 8.713730569948189e-06,
      "loss": 0.7104,
      "step": 1000
    },
    {
      "epoch": 1.36,
      "grad_norm": 87.21064758300781,
      "learning_rate": 8.648963730569949e-06,
      "loss": 0.6137,
      "step": 1050
    },
    {
      "epoch": 1.42,
      "grad_norm": 30.657947540283203,
      "learning_rate": 8.584196891191711e-06,
      "loss": 0.617,
      "step": 1100
    },
    {
      "epoch": 1.49,
      "grad_norm": 110.24565887451172,
      "learning_rate": 8.519430051813472e-06,
      "loss": 0.6197,
      "step": 1150
    },
    {
      "epoch": 1.55,
      "grad_norm": 44.82036209106445,
      "learning_rate": 8.454663212435234e-06,
      "loss": 0.6202,
      "step": 1200
    },
    {
      "epoch": 1.62,
      "grad_norm": 103.00334930419922,
      "learning_rate": 8.389896373056996e-06,
      "loss": 0.6581,
      "step": 1250
    },
    {
      "epoch": 1.68,
      "grad_norm": 30.215347290039062,
      "learning_rate": 8.325129533678757e-06,
      "loss": 0.5979,
      "step": 1300
    },
    {
      "epoch": 1.75,
      "grad_norm": 38.07889175415039,
      "learning_rate": 8.260362694300519e-06,
      "loss": 0.6122,
      "step": 1350
    },
    {
      "epoch": 1.81,
      "grad_norm": 27.705522537231445,
      "learning_rate": 8.19559585492228e-06,
      "loss": 0.6115,
      "step": 1400
    },
    {
      "epoch": 1.88,
      "grad_norm": 34.21351623535156,
      "learning_rate": 8.130829015544042e-06,
      "loss": 0.6168,
      "step": 1450
    },
    {
      "epoch": 1.94,
      "grad_norm": 40.837337493896484,
      "learning_rate": 8.066062176165804e-06,
      "loss": 0.5585,
      "step": 1500
    },
    {
      "epoch": 2.01,
      "grad_norm": 27.512990951538086,
      "learning_rate": 8.001295336787566e-06,
      "loss": 0.6139,
      "step": 1550
    },
    {
      "epoch": 2.07,
      "grad_norm": 519.3585815429688,
      "learning_rate": 7.936528497409327e-06,
      "loss": 0.6033,
      "step": 1600
    },
    {
      "epoch": 2.14,
      "grad_norm": 55.434486389160156,
      "learning_rate": 7.871761658031089e-06,
      "loss": 0.5735,
      "step": 1650
    },
    {
      "epoch": 2.2,
      "grad_norm": 83.93653106689453,
      "learning_rate": 7.80699481865285e-06,
      "loss": 0.5997,
      "step": 1700
    },
    {
      "epoch": 2.27,
      "grad_norm": 61.3811149597168,
      "learning_rate": 7.742227979274613e-06,
      "loss": 0.5954,
      "step": 1750
    },
    {
      "epoch": 2.33,
      "grad_norm": 33.1649284362793,
      "learning_rate": 7.677461139896374e-06,
      "loss": 0.5377,
      "step": 1800
    },
    {
      "epoch": 2.4,
      "grad_norm": 43.79023742675781,
      "learning_rate": 7.612694300518135e-06,
      "loss": 0.5797,
      "step": 1850
    },
    {
      "epoch": 2.46,
      "grad_norm": 21.82843780517578,
      "learning_rate": 7.5479274611398966e-06,
      "loss": 0.5243,
      "step": 1900
    },
    {
      "epoch": 2.53,
      "grad_norm": 39.392539978027344,
      "learning_rate": 7.483160621761658e-06,
      "loss": 0.5736,
      "step": 1950
    },
    {
      "epoch": 2.59,
      "grad_norm": 27.303455352783203,
      "learning_rate": 7.418393782383421e-06,
      "loss": 0.5371,
      "step": 2000
    },
    {
      "epoch": 2.66,
      "grad_norm": 76.2480239868164,
      "learning_rate": 7.353626943005182e-06,
      "loss": 0.5748,
      "step": 2050
    },
    {
      "epoch": 2.72,
      "grad_norm": 38.748050689697266,
      "learning_rate": 7.288860103626944e-06,
      "loss": 0.5555,
      "step": 2100
    },
    {
      "epoch": 2.78,
      "grad_norm": 73.71475982666016,
      "learning_rate": 7.224093264248705e-06,
      "loss": 0.5981,
      "step": 2150
    },
    {
      "epoch": 2.85,
      "grad_norm": 67.28305053710938,
      "learning_rate": 7.1593264248704665e-06,
      "loss": 0.5121,
      "step": 2200
    },
    {
      "epoch": 2.91,
      "grad_norm": 32.078857421875,
      "learning_rate": 7.094559585492229e-06,
      "loss": 0.5381,
      "step": 2250
    },
    {
      "epoch": 2.98,
      "grad_norm": 18.570634841918945,
      "learning_rate": 7.02979274611399e-06,
      "loss": 0.5261,
      "step": 2300
    },
    {
      "epoch": 3.04,
      "grad_norm": 22.853118896484375,
      "learning_rate": 6.9650259067357514e-06,
      "loss": 0.5323,
      "step": 2350
    },
    {
      "epoch": 3.11,
      "grad_norm": 26.66476058959961,
      "learning_rate": 6.900259067357513e-06,
      "loss": 0.5158,
      "step": 2400
    },
    {
      "epoch": 3.17,
      "grad_norm": 26.052873611450195,
      "learning_rate": 6.835492227979276e-06,
      "loss": 0.5211,
      "step": 2450
    },
    {
      "epoch": 3.24,
      "grad_norm": 40.25931167602539,
      "learning_rate": 6.770725388601037e-06,
      "loss": 0.5237,
      "step": 2500
    },
    {
      "epoch": 3.3,
      "grad_norm": 51.03697204589844,
      "learning_rate": 6.705958549222799e-06,
      "loss": 0.5337,
      "step": 2550
    },
    {
      "epoch": 3.37,
      "grad_norm": 25.923879623413086,
      "learning_rate": 6.64119170984456e-06,
      "loss": 0.5195,
      "step": 2600
    },
    {
      "epoch": 3.43,
      "grad_norm": 71.65877532958984,
      "learning_rate": 6.576424870466321e-06,
      "loss": 0.5209,
      "step": 2650
    },
    {
      "epoch": 3.5,
      "grad_norm": 24.67222785949707,
      "learning_rate": 6.5116580310880836e-06,
      "loss": 0.5213,
      "step": 2700
    },
    {
      "epoch": 3.56,
      "grad_norm": 45.06088638305664,
      "learning_rate": 6.446891191709845e-06,
      "loss": 0.5193,
      "step": 2750
    },
    {
      "epoch": 3.63,
      "grad_norm": 27.266542434692383,
      "learning_rate": 6.382124352331607e-06,
      "loss": 0.535,
      "step": 2800
    },
    {
      "epoch": 3.69,
      "grad_norm": 26.373645782470703,
      "learning_rate": 6.3173575129533685e-06,
      "loss": 0.4913,
      "step": 2850
    },
    {
      "epoch": 3.76,
      "grad_norm": 24.268390655517578,
      "learning_rate": 6.25259067357513e-06,
      "loss": 0.5283,
      "step": 2900
    },
    {
      "epoch": 3.82,
      "grad_norm": 53.968379974365234,
      "learning_rate": 6.187823834196892e-06,
      "loss": 0.5009,
      "step": 2950
    },
    {
      "epoch": 3.89,
      "grad_norm": 97.62187194824219,
      "learning_rate": 6.1230569948186535e-06,
      "loss": 0.5104,
      "step": 3000
    },
    {
      "epoch": 3.95,
      "grad_norm": 17.18201446533203,
      "learning_rate": 6.058290155440415e-06,
      "loss": 0.5353,
      "step": 3050
    },
    {
      "epoch": 4.02,
      "grad_norm": 54.66510009765625,
      "learning_rate": 5.993523316062176e-06,
      "loss": 0.52,
      "step": 3100
    },
    {
      "epoch": 4.08,
      "grad_norm": 54.92393112182617,
      "learning_rate": 5.9287564766839376e-06,
      "loss": 0.4984,
      "step": 3150
    },
    {
      "epoch": 4.15,
      "grad_norm": 43.968021392822266,
      "learning_rate": 5.863989637305701e-06,
      "loss": 0.4853,
      "step": 3200
    },
    {
      "epoch": 4.21,
      "grad_norm": 37.97979736328125,
      "learning_rate": 5.799222797927462e-06,
      "loss": 0.5145,
      "step": 3250
    },
    {
      "epoch": 4.27,
      "grad_norm": 66.33306884765625,
      "learning_rate": 5.734455958549223e-06,
      "loss": 0.4991,
      "step": 3300
    },
    {
      "epoch": 4.34,
      "grad_norm": 35.8543586730957,
      "learning_rate": 5.669689119170985e-06,
      "loss": 0.4805,
      "step": 3350
    },
    {
      "epoch": 4.4,
      "grad_norm": 45.443748474121094,
      "learning_rate": 5.604922279792746e-06,
      "loss": 0.4983,
      "step": 3400
    },
    {
      "epoch": 4.47,
      "grad_norm": 27.50312614440918,
      "learning_rate": 5.540155440414508e-06,
      "loss": 0.508,
      "step": 3450
    },
    {
      "epoch": 4.53,
      "grad_norm": 20.670940399169922,
      "learning_rate": 5.47538860103627e-06,
      "loss": 0.4896,
      "step": 3500
    },
    {
      "epoch": 4.6,
      "grad_norm": 25.59025764465332,
      "learning_rate": 5.411917098445596e-06,
      "loss": 0.475,
      "step": 3550
    },
    {
      "epoch": 4.66,
      "grad_norm": 20.53981590270996,
      "learning_rate": 5.347150259067357e-06,
      "loss": 0.4874,
      "step": 3600
    },
    {
      "epoch": 4.73,
      "grad_norm": 45.10053634643555,
      "learning_rate": 5.28238341968912e-06,
      "loss": 0.5134,
      "step": 3650
    },
    {
      "epoch": 4.79,
      "grad_norm": 22.42487144470215,
      "learning_rate": 5.218911917098446e-06,
      "loss": 0.4925,
      "step": 3700
    },
    {
      "epoch": 4.86,
      "grad_norm": 20.136606216430664,
      "learning_rate": 5.154145077720207e-06,
      "loss": 0.5118,
      "step": 3750
    },
    {
      "epoch": 4.92,
      "grad_norm": 46.64333724975586,
      "learning_rate": 5.08937823834197e-06,
      "loss": 0.504,
      "step": 3800
    },
    {
      "epoch": 4.99,
      "grad_norm": 41.24178695678711,
      "learning_rate": 5.024611398963731e-06,
      "loss": 0.4547,
      "step": 3850
    },
    {
      "epoch": 5.05,
      "grad_norm": 71.64462280273438,
      "learning_rate": 4.959844559585493e-06,
      "loss": 0.463,
      "step": 3900
    },
    {
      "epoch": 5.12,
      "grad_norm": 15.852034568786621,
      "learning_rate": 4.895077720207254e-06,
      "loss": 0.4708,
      "step": 3950
    },
    {
      "epoch": 5.18,
      "grad_norm": 35.41175079345703,
      "learning_rate": 4.830310880829016e-06,
      "loss": 0.4916,
      "step": 4000
    },
    {
      "epoch": 5.25,
      "grad_norm": 29.034374237060547,
      "learning_rate": 4.765544041450778e-06,
      "loss": 0.5133,
      "step": 4050
    },
    {
      "epoch": 5.31,
      "grad_norm": 22.492502212524414,
      "learning_rate": 4.700777202072539e-06,
      "loss": 0.4966,
      "step": 4100
    },
    {
      "epoch": 5.38,
      "grad_norm": 26.77665138244629,
      "learning_rate": 4.636010362694301e-06,
      "loss": 0.4648,
      "step": 4150
    },
    {
      "epoch": 5.44,
      "grad_norm": 28.70777702331543,
      "learning_rate": 4.571243523316063e-06,
      "loss": 0.4646,
      "step": 4200
    },
    {
      "epoch": 5.51,
      "grad_norm": 20.154563903808594,
      "learning_rate": 4.506476683937824e-06,
      "loss": 0.4709,
      "step": 4250
    },
    {
      "epoch": 5.57,
      "grad_norm": 73.75604248046875,
      "learning_rate": 4.4417098445595854e-06,
      "loss": 0.4743,
      "step": 4300
    },
    {
      "epoch": 5.63,
      "grad_norm": 46.6107177734375,
      "learning_rate": 4.376943005181348e-06,
      "loss": 0.4612,
      "step": 4350
    },
    {
      "epoch": 5.7,
      "grad_norm": 88.16561126708984,
      "learning_rate": 4.312176165803109e-06,
      "loss": 0.4802,
      "step": 4400
    },
    {
      "epoch": 5.76,
      "grad_norm": 46.28300857543945,
      "learning_rate": 4.24740932642487e-06,
      "loss": 0.4678,
      "step": 4450
    },
    {
      "epoch": 5.83,
      "grad_norm": 35.331790924072266,
      "learning_rate": 4.182642487046633e-06,
      "loss": 0.5003,
      "step": 4500
    },
    {
      "epoch": 5.89,
      "grad_norm": 24.501365661621094,
      "learning_rate": 4.117875647668394e-06,
      "loss": 0.4868,
      "step": 4550
    },
    {
      "epoch": 5.96,
      "grad_norm": 61.58984375,
      "learning_rate": 4.053108808290156e-06,
      "loss": 0.4503,
      "step": 4600
    },
    {
      "epoch": 6.02,
      "grad_norm": 20.190933227539062,
      "learning_rate": 3.9883419689119176e-06,
      "loss": 0.4658,
      "step": 4650
    },
    {
      "epoch": 6.09,
      "grad_norm": 33.987548828125,
      "learning_rate": 3.923575129533679e-06,
      "loss": 0.4732,
      "step": 4700
    },
    {
      "epoch": 6.15,
      "grad_norm": 28.888702392578125,
      "learning_rate": 3.858808290155441e-06,
      "loss": 0.4465,
      "step": 4750
    },
    {
      "epoch": 6.22,
      "grad_norm": 33.317935943603516,
      "learning_rate": 3.794041450777202e-06,
      "loss": 0.4559,
      "step": 4800
    },
    {
      "epoch": 6.28,
      "grad_norm": 22.496919631958008,
      "learning_rate": 3.7292746113989643e-06,
      "loss": 0.4552,
      "step": 4850
    },
    {
      "epoch": 6.35,
      "grad_norm": 27.61361312866211,
      "learning_rate": 3.6645077720207257e-06,
      "loss": 0.4747,
      "step": 4900
    },
    {
      "epoch": 6.41,
      "grad_norm": 18.8084659576416,
      "learning_rate": 3.5997409326424875e-06,
      "loss": 0.4823,
      "step": 4950
    },
    {
      "epoch": 6.48,
      "grad_norm": 146.94931030273438,
      "learning_rate": 3.534974093264249e-06,
      "loss": 0.485,
      "step": 5000
    },
    {
      "epoch": 6.54,
      "grad_norm": 19.736141204833984,
      "learning_rate": 3.4702072538860106e-06,
      "loss": 0.4569,
      "step": 5050
    },
    {
      "epoch": 6.61,
      "grad_norm": 29.728635787963867,
      "learning_rate": 3.4054404145077724e-06,
      "loss": 0.4737,
      "step": 5100
    },
    {
      "epoch": 6.67,
      "grad_norm": 43.64052200317383,
      "learning_rate": 3.340673575129534e-06,
      "loss": 0.4664,
      "step": 5150
    },
    {
      "epoch": 6.74,
      "grad_norm": 17.554018020629883,
      "learning_rate": 3.275906735751296e-06,
      "loss": 0.4723,
      "step": 5200
    },
    {
      "epoch": 6.8,
      "grad_norm": 35.93181228637695,
      "learning_rate": 3.2111398963730574e-06,
      "loss": 0.4807,
      "step": 5250
    },
    {
      "epoch": 6.87,
      "grad_norm": 32.6111946105957,
      "learning_rate": 3.1463730569948188e-06,
      "loss": 0.4692,
      "step": 5300
    },
    {
      "epoch": 6.93,
      "grad_norm": 28.84856605529785,
      "learning_rate": 3.0816062176165805e-06,
      "loss": 0.5037,
      "step": 5350
    },
    {
      "epoch": 6.99,
      "grad_norm": 33.39373779296875,
      "learning_rate": 3.016839378238342e-06,
      "loss": 0.4445,
      "step": 5400
    },
    {
      "epoch": 7.06,
      "grad_norm": 35.9613037109375,
      "learning_rate": 2.952072538860104e-06,
      "loss": 0.4451,
      "step": 5450
    },
    {
      "epoch": 7.12,
      "grad_norm": 52.253257751464844,
      "learning_rate": 2.8873056994818655e-06,
      "loss": 0.4669,
      "step": 5500
    },
    {
      "epoch": 7.19,
      "grad_norm": 59.71750259399414,
      "learning_rate": 2.8225388601036273e-06,
      "loss": 0.4572,
      "step": 5550
    },
    {
      "epoch": 7.25,
      "grad_norm": 34.519187927246094,
      "learning_rate": 2.7577720207253887e-06,
      "loss": 0.4526,
      "step": 5600
    },
    {
      "epoch": 7.32,
      "grad_norm": 99.35079956054688,
      "learning_rate": 2.6930051813471505e-06,
      "loss": 0.4644,
      "step": 5650
    },
    {
      "epoch": 7.38,
      "grad_norm": 21.891510009765625,
      "learning_rate": 2.6282383419689123e-06,
      "loss": 0.4611,
      "step": 5700
    },
    {
      "epoch": 7.45,
      "grad_norm": 15.489242553710938,
      "learning_rate": 2.5634715025906736e-06,
      "loss": 0.4396,
      "step": 5750
    },
    {
      "epoch": 7.51,
      "grad_norm": 36.151798248291016,
      "learning_rate": 2.4987046632124354e-06,
      "loss": 0.4779,
      "step": 5800
    },
    {
      "epoch": 7.58,
      "grad_norm": 50.26751708984375,
      "learning_rate": 2.433937823834197e-06,
      "loss": 0.4667,
      "step": 5850
    },
    {
      "epoch": 7.64,
      "grad_norm": 61.70865249633789,
      "learning_rate": 2.3691709844559586e-06,
      "loss": 0.4554,
      "step": 5900
    },
    {
      "epoch": 7.71,
      "grad_norm": 60.2202262878418,
      "learning_rate": 2.3044041450777204e-06,
      "loss": 0.4615,
      "step": 5950
    },
    {
      "epoch": 7.77,
      "grad_norm": 73.81208038330078,
      "learning_rate": 2.239637305699482e-06,
      "loss": 0.4751,
      "step": 6000
    },
    {
      "epoch": 7.84,
      "grad_norm": 20.9912052154541,
      "learning_rate": 2.1748704663212435e-06,
      "loss": 0.4648,
      "step": 6050
    },
    {
      "epoch": 7.9,
      "grad_norm": 68.354736328125,
      "learning_rate": 2.1101036269430053e-06,
      "loss": 0.4387,
      "step": 6100
    },
    {
      "epoch": 7.97,
      "grad_norm": 28.876564025878906,
      "learning_rate": 2.045336787564767e-06,
      "loss": 0.4539,
      "step": 6150
    },
    {
      "epoch": 8.03,
      "grad_norm": 105.87704467773438,
      "learning_rate": 1.9805699481865285e-06,
      "loss": 0.4414,
      "step": 6200
    },
    {
      "epoch": 8.1,
      "grad_norm": 27.582996368408203,
      "learning_rate": 1.9158031088082903e-06,
      "loss": 0.4387,
      "step": 6250
    },
    {
      "epoch": 8.16,
      "grad_norm": 35.665916442871094,
      "learning_rate": 1.851036269430052e-06,
      "loss": 0.4851,
      "step": 6300
    },
    {
      "epoch": 8.23,
      "grad_norm": 48.974456787109375,
      "learning_rate": 1.7875647668393784e-06,
      "loss": 0.4272,
      "step": 6350
    },
    {
      "epoch": 8.29,
      "grad_norm": 50.07408905029297,
      "learning_rate": 1.72279792746114e-06,
      "loss": 0.4216,
      "step": 6400
    },
    {
      "epoch": 8.35,
      "grad_norm": 28.328086853027344,
      "learning_rate": 1.6580310880829018e-06,
      "loss": 0.4231,
      "step": 6450
    },
    {
      "epoch": 8.42,
      "grad_norm": 28.3199462890625,
      "learning_rate": 1.5932642487046634e-06,
      "loss": 0.4263,
      "step": 6500
    },
    {
      "epoch": 8.48,
      "grad_norm": 22.727685928344727,
      "learning_rate": 1.5284974093264248e-06,
      "loss": 0.4393,
      "step": 6550
    },
    {
      "epoch": 8.55,
      "grad_norm": 34.12513732910156,
      "learning_rate": 1.4637305699481866e-06,
      "loss": 0.4661,
      "step": 6600
    },
    {
      "epoch": 8.61,
      "grad_norm": 18.52674102783203,
      "learning_rate": 1.3989637305699484e-06,
      "loss": 0.434,
      "step": 6650
    },
    {
      "epoch": 8.68,
      "grad_norm": 26.525203704833984,
      "learning_rate": 1.33419689119171e-06,
      "loss": 0.4457,
      "step": 6700
    },
    {
      "epoch": 8.74,
      "grad_norm": 32.68669891357422,
      "learning_rate": 1.2694300518134717e-06,
      "loss": 0.4617,
      "step": 6750
    },
    {
      "epoch": 8.81,
      "grad_norm": 18.299985885620117,
      "learning_rate": 1.2046632124352333e-06,
      "loss": 0.4708,
      "step": 6800
    },
    {
      "epoch": 8.87,
      "grad_norm": 28.287477493286133,
      "learning_rate": 1.139896373056995e-06,
      "loss": 0.4332,
      "step": 6850
    },
    {
      "epoch": 8.94,
      "grad_norm": 418.7196960449219,
      "learning_rate": 1.0751295336787565e-06,
      "loss": 0.4557,
      "step": 6900
    },
    {
      "epoch": 9.0,
      "grad_norm": 21.84061050415039,
      "learning_rate": 1.0103626943005183e-06,
      "loss": 0.4651,
      "step": 6950
    },
    {
      "epoch": 9.07,
      "grad_norm": 44.49687957763672,
      "learning_rate": 9.455958549222799e-07,
      "loss": 0.4182,
      "step": 7000
    },
    {
      "epoch": 9.13,
      "grad_norm": 13.812861442565918,
      "learning_rate": 8.808290155440414e-07,
      "loss": 0.4419,
      "step": 7050
    },
    {
      "epoch": 9.2,
      "grad_norm": 32.561126708984375,
      "learning_rate": 8.160621761658031e-07,
      "loss": 0.4364,
      "step": 7100
    },
    {
      "epoch": 9.26,
      "grad_norm": 24.484230041503906,
      "learning_rate": 7.512953367875648e-07,
      "loss": 0.4387,
      "step": 7150
    },
    {
      "epoch": 9.33,
      "grad_norm": 21.67860984802246,
      "learning_rate": 6.865284974093264e-07,
      "loss": 0.4504,
      "step": 7200
    },
    {
      "epoch": 9.39,
      "grad_norm": 30.596586227416992,
      "learning_rate": 6.217616580310881e-07,
      "loss": 0.4445,
      "step": 7250
    },
    {
      "epoch": 9.46,
      "grad_norm": 54.330284118652344,
      "learning_rate": 5.569948186528498e-07,
      "loss": 0.4306,
      "step": 7300
    },
    {
      "epoch": 9.52,
      "grad_norm": 42.3922233581543,
      "learning_rate": 4.922279792746115e-07,
      "loss": 0.453,
      "step": 7350
    },
    {
      "epoch": 9.59,
      "grad_norm": 42.78515625,
      "learning_rate": 4.274611398963731e-07,
      "loss": 0.4436,
      "step": 7400
    },
    {
      "epoch": 9.65,
      "grad_norm": 30.697053909301758,
      "learning_rate": 3.626943005181347e-07,
      "loss": 0.4242,
      "step": 7450
    },
    {
      "epoch": 9.72,
      "grad_norm": 46.00731658935547,
      "learning_rate": 2.9792746113989635e-07,
      "loss": 0.4432,
      "step": 7500
    },
    {
      "epoch": 9.78,
      "grad_norm": 139.57057189941406,
      "learning_rate": 2.3316062176165804e-07,
      "loss": 0.4131,
      "step": 7550
    },
    {
      "epoch": 9.84,
      "grad_norm": 21.477561950683594,
      "learning_rate": 1.683937823834197e-07,
      "loss": 0.4409,
      "step": 7600
    }
  ],
  "logging_steps": 50,
  "max_steps": 7720,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 200,
  "total_flos": 2.9050480631808e+19,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
